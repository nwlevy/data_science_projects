{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Solar Panel Adoption - Random Forest Models\n",
    "#### UC Berkeley MIDS\n",
    "`Team: Gabriel Hudson, Noah Levy, Laura Williams`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the dataset defined in the Data Set Up notebook, train two Random Forest sequential models:\n",
    "* Random Forest Classifier to predict presence or absence of solar panels  \n",
    "* Random Forest Regressor to predict solar panel density and analyize most important predictive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load curated dataset\n",
    "deepsolar = pd.read_csv('../Datasets/deepsolar_LW1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset rows and dimensions: (71305, 108)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset rows and dimensions:\", deepsolar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Data Set Up\n",
    "\n",
    "* Convert string variables to numeric\n",
    "* Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset rows and dimensions: (71305, 108)\n"
     ]
    }
   ],
   "source": [
    "# Encode string features (county and state) into numeric features\n",
    "LE = preprocessing.LabelEncoder()\n",
    "\n",
    "LE.fit(deepsolar['county'])\n",
    "deepsolar['county'] = LE.transform(deepsolar['county'])\n",
    "\n",
    "LE.fit(deepsolar['state'])\n",
    "deepsolar['state'] = LE.transform(deepsolar['state'])\n",
    "\n",
    "print(\"Dataset rows and dimensions:\", deepsolar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize\n",
    "deepsolar = (deepsolar - deepsolar.mean())/(deepsolar.max() - deepsolar.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data\n",
    "\n",
    "* Define outcome variables\n",
    "* Split into test/train/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create binary outcome variable for stage 1 RF classifier\n",
    "deepsolar['solar_flag']=deepsolar['number_of_solar_system_per_household'].apply(lambda x: int(x>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New binary outcome variable for Stage 1 random forest classifier 'solar_flag' has 2 values: 0 and 1\n"
     ]
    }
   ],
   "source": [
    "# Confirm values in new outcome variable\n",
    "print(\"New binary outcome variable for Stage 1 random forest classifier 'solar_flag' has\", \n",
    "      deepsolar['solar_flag'].nunique(), \"values:\", deepsolar[\"solar_flag\"].min(),\n",
    "      \"and\", deepsolar[\"solar_flag\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random shuffle and split data into test, training and development sets. Test data will not be used until model and dataset has been optimized on the training and development datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full featureset shape is (71305, 107)\n",
      "Classifier outcome variable shape: (71305,)\n",
      "Regressor outcome variable shape: (71305,)\n"
     ]
    }
   ],
   "source": [
    "# separate outcome variables and features\n",
    "X = deepsolar.drop(labels=['solar_flag', 'number_of_solar_system_per_household'], axis=1).values\n",
    "Y_classifier = deepsolar['solar_flag'].values\n",
    "Y_regressor = deepsolar['number_of_solar_system_per_household'].values\n",
    "print(\"Full featureset shape is\", X.shape)\n",
    "print(\"Classifier outcome variable shape:\", Y_classifier.shape)\n",
    "print(\"Regressor outcome variable shape:\", Y_regressor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:               \t(45635, 107)\n",
      "Training outcome variable - classifier:\t(45635,)\n",
      "Training outcome variable - regressor:\t(45635,)\n",
      "Dev data shape:                    \t(11409, 107)\n",
      "Dev outcome variable - classifier: \t(11409,)\n",
      "Dev outcome variable - regressor:  \t(11409,)\n",
      "Test data shape:                   \t(14261, 107)\n",
      "Test outcome variable - classifier:\t(14261,)\n",
      "Test outcome variable - regressor: \t(14261,)\n"
     ]
    }
   ],
   "source": [
    "# set a random seed to keep the split the same \n",
    "np.random.seed(0)\n",
    "\n",
    "# shuffle data\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X = X[shuffle]\n",
    "Y_classifier = Y_classifier[shuffle]\n",
    "Y_regressor = Y_regressor[shuffle]\n",
    "\n",
    "# split data and labels into test set and initial training set\n",
    "n_train = int(0.8*X.shape[0])\n",
    "X_train1 = X[:n_train,:]\n",
    "X_test = X[n_train:,:]\n",
    "Y_classifier_train1 = Y_classifier[:n_train]\n",
    "Y_classifier_test = Y_classifier[n_train:]\n",
    "Y_regressor_train1 = Y_regressor[:n_train]\n",
    "Y_regressor_test = Y_regressor[n_train:]\n",
    "\n",
    "# split training data and labels into training and development sets\n",
    "n_train = int(0.8*X_train1.shape[0])\n",
    "X_train = X_train1[:n_train,:]\n",
    "X_dev = X_train1[n_train:,:]\n",
    "Y_classifier_train = Y_classifier_train1[:n_train]\n",
    "Y_classifier_dev = Y_classifier_train1[n_train:]\n",
    "Y_regressor_train = Y_regressor_train1[:n_train]\n",
    "Y_regressor_dev = Y_regressor_train1[n_train:]\n",
    "\n",
    "print(\"{:<35}\\t{}\".format(\"Training data shape:\", X_train.shape))\n",
    "print(\"{:<35}\\t{}\".format(\"Training outcome variable - classifier:\",Y_classifier_train.shape ))\n",
    "print(\"{:<35}\\t{}\".format(\"Training outcome variable - regressor:\",Y_regressor_train.shape ))\n",
    "print(\"{:<35}\\t{}\".format(\"Dev data shape:\", X_dev.shape))\n",
    "print(\"{:<35}\\t{}\".format(\"Dev outcome variable - classifier:\",Y_classifier_dev.shape ))\n",
    "print(\"{:<35}\\t{}\".format(\"Dev outcome variable - regressor:\",Y_regressor_dev.shape ))\n",
    "print(\"{:<35}\\t{}\".format(\"Test data shape:\", X_test.shape))\n",
    "print(\"{:<35}\\t{}\".format(\"Test outcome variable - classifier:\",Y_classifier_test.shape ))\n",
    "print(\"{:<35}\\t{}\".format(\"Test outcome variable - regressor:\",Y_regressor_test.shape ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use best parameters from Noah's hyperparameter tuning\n",
    "n = 100\n",
    "depth = None\n",
    "features = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "RF1_Classifier = RandomForestClassifier(n_estimators=n, max_depth=depth, max_features=features, n_jobs=1)\n",
    "RF1_Classifier.fit(X_train, Y_classifier_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93382417389780004"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R squared\n",
    "RF1_Classifier.score(X_dev,Y_classifier_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: Feature Importances for the Classifier, then train the Regressor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
